{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f584ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All directories created successfully\n",
      "\n",
      "================================================================================\n",
      "üöÄ ENHANCED STOCK PRICE PREDICTION SYSTEM WITH ENSEMBLE AI\n",
      "================================================================================\n",
      "üìå Features: Multi-Model Ensemble | Advanced Technical Analysis | Confidence Intervals\n",
      "================================================================================\n",
      "\n",
      "üìä AVAILABLE STOCKS FOR ANALYSIS:\n",
      "--------------------------------------------------------------------------------\n",
      "   AAPL     - Apple Inc.                       MSFT     - Microsoft Corporation            GOOGL    - Alphabet Inc.                    \n",
      "   AMZN     - Amazon.com Inc.                  TSLA     - Tesla Inc.                       META     - Meta Platforms Inc.              \n",
      "   NVDA     - NVIDIA Corporation               JPM      - JPMorgan Chase & Co.             V        - Visa Inc.                        \n",
      "   WMT      - Walmart Inc.                     DIS      - The Walt Disney Company          NFLX     - Netflix Inc.                     \n",
      "   INTC     - Intel Corporation                AMD      - Advanced Micro Devices           PYPL     - PayPal Holdings Inc.             \n",
      "\n",
      "================================================================================\n",
      "‚úÖ Found: AAPL - Apple Inc.\n",
      "\n",
      "================================================================================\n",
      "‚úÖ SELECTED: AAPL - Apple Inc.\n",
      "================================================================================\n",
      "\n",
      "üì• Downloading historical stock data...\n",
      "‚úÖ Successfully downloaded 1256 trading days\n",
      "üìÖ Date range: 2020-10-26 to 2025-10-24\n",
      "üíæ Raw data saved: Training/stock_data/AAPL_raw_data.csv\n",
      "\n",
      "================================================================================\n",
      "ü§ñ TRAINING ENHANCED ENSEMBLE AI MODEL\n",
      "================================================================================\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîÑ Training ensemble model for 1 Day prediction...\n",
      "\n",
      "‚ùå An error occurred: Can only compare identically-labeled Series objects\n",
      "\n",
      "üí° Please check your internet connection and try again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12280\\3314353156.py\", line 1128, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12280\\3314353156.py\", line 909, in main\n",
      "    if predictor.train_ensemble_model(data, horizon):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12280\\3314353156.py\", line 390, in train_ensemble_model\n",
      "    directional_accuracy = (actual_direction == pred_direction).sum() / len(actual_direction) * 100\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\ops\\common.py\", line 76, in new_method\n",
      "    return method(self, other)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\arraylike.py\", line 40, in __eq__\n",
      "    return self._cmp_method(other, operator.eq)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py\", line 6114, in _cmp_method\n",
      "    raise ValueError(\"Can only compare identically-labeled Series objects\")\n",
      "ValueError: Can only compare identically-labeled Series objects\n"
     ]
    }
   ],
   "source": [
    "#-------------------[IMPORT MODULES]-----------------------#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#-------------------[STOCK DATABASE]-----------------------#\n",
    "STOCK_DATABASE = {\n",
    "    'AAPL': 'Apple Inc.',\n",
    "    'MSFT': 'Microsoft Corporation',\n",
    "    'GOOGL': 'Alphabet Inc.',\n",
    "    'AMZN': 'Amazon.com Inc.',\n",
    "    'TSLA': 'Tesla Inc.',\n",
    "    'META': 'Meta Platforms Inc.',\n",
    "    'NVDA': 'NVIDIA Corporation',\n",
    "    'JPM': 'JPMorgan Chase & Co.',\n",
    "    'V': 'Visa Inc.',\n",
    "    'WMT': 'Walmart Inc.',\n",
    "    'DIS': 'The Walt Disney Company',\n",
    "    'NFLX': 'Netflix Inc.',\n",
    "    'INTC': 'Intel Corporation',\n",
    "    'AMD': 'Advanced Micro Devices',\n",
    "    'PYPL': 'PayPal Holdings Inc.'\n",
    "}\n",
    "\n",
    "def load_stock_list():\n",
    "    \"\"\"Load stock list from database\"\"\"\n",
    "    return STOCK_DATABASE\n",
    "\n",
    "#-------------------[TECHNICAL INDICATORS FUNCTIONS]-----------------------#\n",
    "def calculate_technical_indicators(data):\n",
    "    \"\"\"Calculate comprehensive technical indicators\"\"\"\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Flatten MultiIndex columns if present\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "    \n",
    "    # Ensure we're working with Series\n",
    "    close = df['Close'].squeeze()\n",
    "    high = df['High'].squeeze()\n",
    "    low = df['Low'].squeeze()\n",
    "    volume = df['Volume'].squeeze()\n",
    "    \n",
    "    # Moving Averages\n",
    "    for period in [7, 20, 50, 100, 200]:\n",
    "        df[f'MA_{period}'] = close.rolling(period).mean()\n",
    "        df[f'MA_{period}_slope'] = df[f'MA_{period}'].diff(5)\n",
    "    \n",
    "    # Exponential Moving Averages\n",
    "    for period in [12, 26, 50]:\n",
    "        df[f'EMA_{period}'] = close.ewm(span=period, adjust=False).mean()\n",
    "    \n",
    "    # MACD\n",
    "    ema_12 = close.ewm(span=12, adjust=False).mean()\n",
    "    ema_26 = close.ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = ema_12 - ema_26\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']\n",
    "    \n",
    "    # RSI (Multiple periods)\n",
    "    for period in [14, 21]:\n",
    "        delta = close.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "        rs = gain / (loss + 1e-10)  # Avoid division by zero\n",
    "        df[f'RSI_{period}'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    for period in [20, 50]:\n",
    "        bb_middle = close.rolling(period).mean()\n",
    "        bb_std = close.rolling(period).std()\n",
    "        df[f'BB_Middle_{period}'] = bb_middle\n",
    "        df[f'BB_Upper_{period}'] = bb_middle + (bb_std * 2)\n",
    "        df[f'BB_Lower_{period}'] = bb_middle - (bb_std * 2)\n",
    "        df[f'BB_Width_{period}'] = (df[f'BB_Upper_{period}'] - df[f'BB_Lower_{period}']) / bb_middle\n",
    "        df[f'BB_Position_{period}'] = (close - df[f'BB_Lower_{period}']) / (df[f'BB_Upper_{period}'] - df[f'BB_Lower_{period}'] + 1e-10)\n",
    "    \n",
    "    # Stochastic Oscillator\n",
    "    low_14 = low.rolling(14).min()\n",
    "    high_14 = high.rolling(14).max()\n",
    "    df['Stochastic_%K'] = 100 * (close - low_14) / (high_14 - low_14 + 1e-10)\n",
    "    df['Stochastic_%D'] = df['Stochastic_%K'].rolling(3).mean()\n",
    "    \n",
    "    # ATR (Average True Range)\n",
    "    high_low = high - low\n",
    "    high_close = np.abs(high - close.shift())\n",
    "    low_close = np.abs(low - close.shift())\n",
    "    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "    true_range = ranges.max(axis=1)\n",
    "    df['ATR_14'] = true_range.rolling(14).mean()\n",
    "    \n",
    "    # Volume indicators\n",
    "    df['Volume_MA_20'] = volume.rolling(20).mean()\n",
    "    df['Volume_MA_50'] = volume.rolling(50).mean()\n",
    "    df['Volume_Ratio'] = volume / (df['Volume_MA_20'] + 1)\n",
    "    \n",
    "    # OBV (On-Balance Volume)\n",
    "    df['OBV'] = (np.sign(close.diff()) * volume).fillna(0).cumsum()\n",
    "    df['OBV_MA'] = df['OBV'].rolling(20).mean()\n",
    "    \n",
    "    # Money Flow Index\n",
    "    typical_price = (high + low + close) / 3\n",
    "    money_flow = typical_price * volume\n",
    "    \n",
    "    positive_flow = money_flow.where(typical_price > typical_price.shift(1), 0).rolling(14).sum()\n",
    "    negative_flow = money_flow.where(typical_price < typical_price.shift(1), 0).rolling(14).sum()\n",
    "    df['MFI'] = 100 - (100 / (1 + positive_flow / (negative_flow + 1e-10)))\n",
    "    \n",
    "    # ADX (Average Directional Index)\n",
    "    plus_dm = high.diff()\n",
    "    minus_dm = low.diff().abs()\n",
    "    plus_dm = plus_dm.where((plus_dm > minus_dm) & (plus_dm > 0), 0)\n",
    "    minus_dm = minus_dm.where((minus_dm > plus_dm.abs()) & (minus_dm > 0), 0)\n",
    "    \n",
    "    tr = true_range.rolling(14).sum()\n",
    "    plus_di = 100 * (plus_dm.rolling(14).sum() / tr)\n",
    "    minus_di = 100 * (minus_dm.rolling(14).sum() / tr)\n",
    "    \n",
    "    dx = 100 * np.abs(plus_di - minus_di) / (plus_di + minus_di + 1e-10)\n",
    "    df['ADX'] = dx.rolling(14).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "#-------------------[ENHANCED STOCK PREDICTION CLASS]-----------------------#\n",
    "class EnhancedStockPricePredictor:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.ensemble_weights = {}\n",
    "        self.scaler = RobustScaler()  # More robust to outliers\n",
    "        self.feature_columns = None\n",
    "        self.feature_importance = None\n",
    "        self.is_trained = False\n",
    "        self.ticker = None\n",
    "        self.company_name = None\n",
    "        self.training_metrics = {}\n",
    "        self.validation_results = {}\n",
    "    \n",
    "    def prepare_features(self, data):\n",
    "        \"\"\"Enhanced feature engineering with advanced technical analysis\"\"\"\n",
    "        df = data.copy()\n",
    "        \n",
    "        # Flatten MultiIndex columns if present\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "            \n",
    "        # Ensure we're working with Series\n",
    "        close = df['Close'].squeeze()\n",
    "        open_price = df['Open'].squeeze()\n",
    "        high = df['High'].squeeze()\n",
    "        low = df['Low'].squeeze()\n",
    "        volume = df['Volume'].squeeze()\n",
    "        \n",
    "        # Price-based features\n",
    "        df['Price_Range'] = high - low\n",
    "        df['Price_Change'] = close - open_price\n",
    "        df['Price_Change_Pct'] = (close - open_price) / (open_price + 1e-10) * 100\n",
    "        df['Close_Open_Ratio'] = close / (open_price + 1e-10)\n",
    "        df['High_Low_Ratio'] = high / (low + 1e-10)\n",
    "        df['High_Close_Ratio'] = high / (close + 1e-10)\n",
    "        df['Low_Close_Ratio'] = low / (close + 1e-10)\n",
    "        \n",
    "        # Intraday features\n",
    "        df['Upper_Shadow'] = high - np.maximum(close, open_price)\n",
    "        df['Lower_Shadow'] = np.minimum(close, open_price) - low\n",
    "        df['Body_Size'] = np.abs(close - open_price)\n",
    "        \n",
    "        # Moving Averages and crossovers\n",
    "        for window in [5, 7, 10, 15, 20, 30, 50, 100, 200]:\n",
    "            ma = close.rolling(window).mean()\n",
    "            df[f'MA_{window}'] = ma\n",
    "            df[f'Price_vs_MA_{window}'] = (close - ma) / (ma + 1e-10) * 100\n",
    "            df[f'MA_{window}_Trend'] = ma.diff(5)\n",
    "        \n",
    "        # MA crossovers\n",
    "        df['MA_5_20_Cross'] = (df['MA_5'] - df['MA_20']) / (df['MA_20'] + 1e-10)\n",
    "        df['MA_20_50_Cross'] = (df['MA_20'] - df['MA_50']) / (df['MA_50'] + 1e-10)\n",
    "        df['MA_50_200_Cross'] = (df['MA_50'] - df['MA_200']) / (df['MA_200'] + 1e-10)\n",
    "        \n",
    "        # Exponential Moving Averages\n",
    "        for span in [8, 12, 21, 26, 50, 100]:\n",
    "            ema = close.ewm(span=span, adjust=False).mean()\n",
    "            df[f'EMA_{span}'] = ema\n",
    "            df[f'Price_vs_EMA_{span}'] = (close - ema) / (ema + 1e-10) * 100\n",
    "        \n",
    "        # MACD variations\n",
    "        ema_12 = close.ewm(span=12, adjust=False).mean()\n",
    "        ema_26 = close.ewm(span=26, adjust=False).mean()\n",
    "        macd = ema_12 - ema_26\n",
    "        df['MACD'] = macd\n",
    "        df['MACD_Signal'] = macd.ewm(span=9, adjust=False).mean()\n",
    "        df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']\n",
    "        df['MACD_Histogram_Change'] = df['MACD_Histogram'].diff()\n",
    "        \n",
    "        # RSI for multiple periods\n",
    "        for period in [9, 14, 21, 28]:\n",
    "            delta = close.diff()\n",
    "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "            rs = gain / (loss + 1e-10)\n",
    "            df[f'RSI_{period}'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        for period in [20, 50]:\n",
    "            bb_middle = close.rolling(period).mean()\n",
    "            bb_std = close.rolling(period).std()\n",
    "            df[f'BB_Middle_{period}'] = bb_middle\n",
    "            df[f'BB_Upper_{period}'] = bb_middle + (bb_std * 2)\n",
    "            df[f'BB_Lower_{period}'] = bb_middle - (bb_std * 2)\n",
    "            df[f'BB_Width_{period}'] = (df[f'BB_Upper_{period}'] - df[f'BB_Lower_{period}']) / (bb_middle + 1e-10)\n",
    "            df[f'BB_Position_{period}'] = (close - df[f'BB_Lower_{period}']) / (df[f'BB_Upper_{period}'] - df[f'BB_Lower_{period}'] + 1e-10)\n",
    "        \n",
    "        # Stochastic Oscillator\n",
    "        low_14 = low.rolling(14).min()\n",
    "        high_14 = high.rolling(14).max()\n",
    "        df['Stochastic_%K'] = 100 * (close - low_14) / (high_14 - low_14 + 1e-10)\n",
    "        df['Stochastic_%D'] = df['Stochastic_%K'].rolling(3).mean()\n",
    "        \n",
    "        # Volume indicators\n",
    "        for window in [10, 20, 50]:\n",
    "            volume_ma = volume.rolling(window).mean()\n",
    "            df[f'Volume_MA_{window}'] = volume_ma\n",
    "            df[f'Volume_Ratio_{window}'] = volume / (volume_ma + 1)\n",
    "        \n",
    "        # OBV\n",
    "        df['OBV'] = (np.sign(close.diff()) * volume).fillna(0).cumsum()\n",
    "        df['OBV_MA'] = df['OBV'].rolling(20).mean()\n",
    "        df['OBV_Trend'] = df['OBV'] - df['OBV_MA']\n",
    "        \n",
    "        # Momentum indicators\n",
    "        for period in [5, 10, 15, 20, 30]:\n",
    "            df[f'Momentum_{period}'] = close.diff(period)\n",
    "            df[f'ROC_{period}'] = ((close - close.shift(period)) / (close.shift(period) + 1e-10)) * 100\n",
    "        \n",
    "        # Volatility measures\n",
    "        for period in [10, 20, 30]:\n",
    "            df[f'Volatility_{period}'] = close.rolling(period).std()\n",
    "            df[f'Volatility_{period}_Norm'] = df[f'Volatility_{period}'] / (close + 1e-10) * 100\n",
    "        \n",
    "        # Historical Volatility (Parkinson)\n",
    "        df['Parkinson_Volatility'] = np.sqrt(1/(4*np.log(2)) * ((np.log(high/low))**2).rolling(20).mean())\n",
    "        \n",
    "        # Daily returns and statistics\n",
    "        df['Daily_Return'] = close.pct_change()\n",
    "        df['Daily_Return_Squared'] = df['Daily_Return'] ** 2\n",
    "        for period in [5, 10, 20]:\n",
    "            df[f'Return_Mean_{period}'] = df['Daily_Return'].rolling(period).mean()\n",
    "            df[f'Return_Std_{period}'] = df['Daily_Return'].rolling(period).std()\n",
    "        \n",
    "        # Price patterns\n",
    "        df['Higher_High'] = (high > high.shift(1)).astype(int)\n",
    "        df['Lower_Low'] = (low < low.shift(1)).astype(int)\n",
    "        df['Higher_Close'] = (close > close.shift(1)).astype(int)\n",
    "        \n",
    "        # Lag features (multiple periods)\n",
    "        for lag in [1, 2, 3, 5, 7, 10]:\n",
    "            df[f'Close_Lag_{lag}'] = close.shift(lag)\n",
    "            df[f'Volume_Lag_{lag}'] = volume.shift(lag)\n",
    "            df[f'Return_Lag_{lag}'] = df['Daily_Return'].shift(lag)\n",
    "        \n",
    "        # Rolling statistics\n",
    "        for window in [5, 10, 20]:\n",
    "            df[f'Close_Max_{window}'] = close.rolling(window).max()\n",
    "            df[f'Close_Min_{window}'] = close.rolling(window).min()\n",
    "            df[f'Close_Std_{window}'] = close.rolling(window).std()\n",
    "            df[f'Price_Position_{window}'] = (close - df[f'Close_Min_{window}']) / (df[f'Close_Max_{window}'] - df[f'Close_Min_{window}'] + 1e-10)\n",
    "        \n",
    "        # Target variables for different time horizons\n",
    "        df['Target_1_Day'] = close.shift(-1)\n",
    "        df['Target_5_Days'] = close.shift(-5)\n",
    "        df['Target_21_Days'] = close.shift(-21)\n",
    "        \n",
    "        # Target percentage changes\n",
    "        df['Target_1_Day_Pct'] = ((df['Target_1_Day'] - close) / close) * 100\n",
    "        df['Target_5_Days_Pct'] = ((df['Target_5_Days'] - close) / close) * 100\n",
    "        df['Target_21_Days_Pct'] = ((df['Target_21_Days'] - close) / close) * 100\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def train_ensemble_model(self, data, target_horizon='1_Day'):\n",
    "        \"\"\"Train an ensemble of models for better predictions\"\"\"\n",
    "        print(f\"üîÑ Training ensemble model for {target_horizon.replace('_', ' ')} prediction...\")\n",
    "        \n",
    "        # Prepare features\n",
    "        data_with_features = self.prepare_features(data)\n",
    "        data_clean = data_with_features.dropna()\n",
    "        \n",
    "        if len(data_clean) < 100:\n",
    "            print(f\"‚ùå Insufficient data for training (need at least 100 samples, got {len(data_clean)})\")\n",
    "            return False\n",
    "        \n",
    "        # Define feature columns (select most relevant features)\n",
    "        feature_candidates = [col for col in data_clean.columns \n",
    "                            if col not in ['Target_1_Day', 'Target_5_Days', 'Target_21_Days',\n",
    "                                         'Target_1_Day_Pct', 'Target_5_Days_Pct', 'Target_21_Days_Pct']]\n",
    "        \n",
    "        # Remove columns with too many NaN or inf values\n",
    "        available_features = []\n",
    "        for col in feature_candidates:\n",
    "            if data_clean[col].replace([np.inf, -np.inf], np.nan).notna().sum() > len(data_clean) * 0.8:\n",
    "                available_features.append(col)\n",
    "        \n",
    "        target_column = f'Target_{target_horizon}'\n",
    "        \n",
    "        if target_column not in data_clean.columns:\n",
    "            print(f\"‚ùå Target column {target_column} not found!\")\n",
    "            return False\n",
    "        \n",
    "        # Prepare data\n",
    "        X = data_clean[available_features].replace([np.inf, -np.inf], np.nan).fillna(method='ffill').fillna(method='bfill')\n",
    "        y = data_clean[target_column]\n",
    "        \n",
    "        # Time series split for validation\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "        # Store all validation scores\n",
    "        all_scores = {'rf': [], 'gb': [], 'ridge': []}\n",
    "        \n",
    "        for train_idx, val_idx in tscv.split(X):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            # Scale features\n",
    "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "            X_val_scaled = self.scaler.transform(X_val)\n",
    "            \n",
    "            # Train multiple models\n",
    "            models = {\n",
    "                'rf': RandomForestRegressor(n_estimators=200, max_depth=20, min_samples_split=5,\n",
    "                                           min_samples_leaf=2, random_state=42, n_jobs=-1),\n",
    "                'gb': GradientBoostingRegressor(n_estimators=200, max_depth=5, learning_rate=0.05,\n",
    "                                               subsample=0.8, random_state=42),\n",
    "                'ridge': Ridge(alpha=1.0, random_state=42)\n",
    "            }\n",
    "            \n",
    "            for name, model in models.items():\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                val_pred = model.predict(X_val_scaled)\n",
    "                mae = mean_absolute_error(y_val, val_pred)\n",
    "                all_scores[name].append(mae)\n",
    "        \n",
    "        # Calculate average scores and weights\n",
    "        avg_scores = {name: np.mean(scores) for name, scores in all_scores.items()}\n",
    "        inverse_scores = {name: 1/score for name, score in avg_scores.items()}\n",
    "        total_inverse = sum(inverse_scores.values())\n",
    "        weights = {name: inv/total_inverse for name, inv in inverse_scores.items()}\n",
    "        \n",
    "        # Train final models on all data\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        final_models = {\n",
    "            'rf': RandomForestRegressor(n_estimators=200, max_depth=20, min_samples_split=5,\n",
    "                                       min_samples_leaf=2, random_state=42, n_jobs=-1),\n",
    "            'gb': GradientBoostingRegressor(n_estimators=200, max_depth=5, learning_rate=0.05,\n",
    "                                           subsample=0.8, random_state=42),\n",
    "            'ridge': Ridge(alpha=1.0, random_state=42)\n",
    "        }\n",
    "        \n",
    "        for name, model in final_models.items():\n",
    "            model.fit(X_scaled, y)\n",
    "        \n",
    "        # Store models and weights\n",
    "        self.models[target_horizon] = final_models\n",
    "        self.ensemble_weights[target_horizon] = weights\n",
    "        \n",
    "        # Evaluate ensemble\n",
    "        ensemble_pred = np.zeros(len(y))\n",
    "        for name, model in final_models.items():\n",
    "            ensemble_pred += model.predict(X_scaled) * weights[name]\n",
    "        \n",
    "        mae = mean_absolute_error(y, ensemble_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "        r2 = r2_score(y, ensemble_pred)\n",
    "        mape = mean_absolute_percentage_error(y, ensemble_pred)\n",
    "        \n",
    "        # Calculate directional accuracy\n",
    "        actual_direction = (y.diff() > 0).astype(int)\n",
    "        pred_direction = (pd.Series(ensemble_pred).diff() > 0).astype(int)\n",
    "        directional_accuracy = (actual_direction == pred_direction).sum() / len(actual_direction) * 100\n",
    "        \n",
    "        # Store metrics\n",
    "        self.training_metrics[target_horizon] = {\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2_score': r2,\n",
    "            'mape': mape,\n",
    "            'directional_accuracy': directional_accuracy,\n",
    "            'ensemble_weights': weights,\n",
    "            'model_scores': avg_scores\n",
    "        }\n",
    "        \n",
    "        # Feature importance (from Random Forest)\n",
    "        if hasattr(final_models['rf'], 'feature_importances_'):\n",
    "            feature_imp = pd.DataFrame({\n",
    "                'feature': available_features,\n",
    "                'importance': final_models['rf'].feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            self.feature_importance = feature_imp\n",
    "        \n",
    "        print(f\"üìà Ensemble Model Performance ({target_horizon.replace('_', ' ')}):\")\n",
    "        print(f\"   MAE: ${mae:.2f} | RMSE: ${rmse:.2f} | R¬≤: {r2:.4f} | MAPE: {mape:.2f}%\")\n",
    "        print(f\"   Directional Accuracy: {directional_accuracy:.1f}%\")\n",
    "        print(f\"   Ensemble Weights: RF={weights['rf']:.2f}, GB={weights['gb']:.2f}, Ridge={weights['ridge']:.2f}\")\n",
    "        \n",
    "        self.is_trained = True\n",
    "        self.feature_columns = available_features\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def predict_future(self, data, target_horizon='1_Day'):\n",
    "        \"\"\"Predict future stock prices using ensemble\"\"\"\n",
    "        if not self.is_trained or target_horizon not in self.models:\n",
    "            print(f\"‚ùå Model for {target_horizon} not trained!\")\n",
    "            return None\n",
    "        \n",
    "        # Prepare features\n",
    "        data_with_features = self.prepare_features(data)\n",
    "        latest_data = data_with_features[self.feature_columns].iloc[-1:].replace([np.inf, -np.inf], np.nan).fillna(method='ffill').fillna(0)\n",
    "        \n",
    "        # Scale features\n",
    "        latest_data_scaled = self.scaler.transform(latest_data)\n",
    "        \n",
    "        # Ensemble prediction\n",
    "        ensemble_pred = 0\n",
    "        for name, model in self.models[target_horizon].items():\n",
    "            pred = model.predict(latest_data_scaled)[0]\n",
    "            weight = self.ensemble_weights[target_horizon][name]\n",
    "            ensemble_pred += pred * weight\n",
    "        \n",
    "        # Get current price\n",
    "        if isinstance(data['Close'], pd.DataFrame):\n",
    "            current_price = data['Close'].iloc[-1].values[0]\n",
    "        else:\n",
    "            current_price = data['Close'].iloc[-1]\n",
    "        \n",
    "        # Calculate confidence interval (using prediction std)\n",
    "        predictions = [model.predict(latest_data_scaled)[0] for model in self.models[target_horizon].values()]\n",
    "        pred_std = np.std(predictions)\n",
    "        \n",
    "        return {\n",
    "            'current_price': current_price,\n",
    "            'predicted_price': ensemble_pred,\n",
    "            'price_change': ensemble_pred - current_price,\n",
    "            'price_change_pct': ((ensemble_pred / current_price) - 1) * 100,\n",
    "            'confidence_lower': ensemble_pred - 1.96 * pred_std,\n",
    "            'confidence_upper': ensemble_pred + 1.96 * pred_std,\n",
    "            'prediction_std': pred_std\n",
    "        }\n",
    "\n",
    "#-------------------[FIND STOCK]-----------------------#\n",
    "def find_stock(search_term):\n",
    "    \"\"\"Find stock in database\"\"\"\n",
    "    matches = {}\n",
    "    stock_list = load_stock_list()\n",
    "    \n",
    "    for symbol, name in stock_list.items():\n",
    "        if (search_term.upper() in symbol.upper() or \n",
    "            search_term.lower() in name.lower()):\n",
    "            matches[symbol] = name\n",
    "    \n",
    "    return matches\n",
    "\n",
    "#-------------------[CREATE DIRECTORIES]-----------------------#\n",
    "def create_directories():\n",
    "    \"\"\"Create necessary directories\"\"\"\n",
    "    directories = ['Training/stock_data', 'Training/models', 'Training/charts']\n",
    "    for directory in directories:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    print(\"‚úì All directories created successfully\")\n",
    "\n",
    "#-------------------[ENHANCED VISUALIZATION]-----------------------#\n",
    "def visualize_with_predictions(data, ticker, company_name, predictions, predictor):\n",
    "    \"\"\"Create comprehensive visualizations with prediction results\"\"\"\n",
    "    print(\"\\nüìä Generating enhanced visualizations with predictions...\")\n",
    "    \n",
    "    # Calculate technical indicators\n",
    "    data_with_indicators = calculate_technical_indicators(data)\n",
    "    data_clean = data_with_indicators.dropna()\n",
    "    \n",
    "    # Get current price\n",
    "    if isinstance(data['Close'], pd.DataFrame):\n",
    "        current_price = data['Close'].iloc[-1].values[0]\n",
    "    else:\n",
    "        current_price = data['Close'].iloc[-1]\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(22, 18))\n",
    "    gs = fig.add_gridspec(6, 2, hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    # 1. Main Price Chart with Predictions and Confidence Intervals\n",
    "    ax1 = fig.add_subplot(gs[0:2, :])\n",
    "    ax1.plot(data_clean.index, data_clean['Close'], label='Historical Price', color='blue', linewidth=2.5)\n",
    "    ax1.plot(data_clean.index, data_clean['MA_50'], label='MA 50', color='red', linewidth=1.5, alpha=0.7)\n",
    "    ax1.plot(data_clean.index, data_clean['MA_200'], label='MA 200', color='green', linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    # Add Bollinger Bands\n",
    "    ax1.fill_between(data_clean.index, data_clean['BB_Upper_20'], data_clean['BB_Lower_20'], \n",
    "                     alpha=0.1, color='gray', label='Bollinger Bands')\n",
    "    \n",
    "    # Add prediction markers with confidence intervals\n",
    "    last_date = data_clean.index[-1]\n",
    "    ax1.scatter(last_date, current_price, color='blue', s=250, zorder=5, marker='o', \n",
    "               edgecolors='black', linewidths=2, label='Current Price')\n",
    "    \n",
    "    colors = {'1 Day': 'orange', '1 Week': 'purple', '1 Month': 'red'}\n",
    "    offsets = {'1 Day': 1, '1 Week': 5, '1 Month': 21}\n",
    "    \n",
    "    for horizon, pred in predictions.items():\n",
    "        future_date = last_date + timedelta(days=offsets[horizon])\n",
    "        \n",
    "        # Main prediction\n",
    "        ax1.scatter(future_date, pred['predicted_price'], color=colors[horizon], \n",
    "                   s=250, zorder=5, marker='*', edgecolors='black', linewidths=2,\n",
    "                   label=f'{horizon} Prediction')\n",
    "        \n",
    "        # Confidence interval\n",
    "        ax1.errorbar(future_date, pred['predicted_price'], \n",
    "                    yerr=[[pred['predicted_price'] - pred['confidence_lower']], \n",
    "                          [pred['confidence_upper'] - pred['predicted_price']]], \n",
    "                    fmt='none', ecolor=colors[horizon], elinewidth=2, capsize=5, alpha=0.6)\n",
    "        \n",
    "        # Prediction line\n",
    "        ax1.plot([last_date, future_date], [current_price, pred['predicted_price']], \n",
    "                color=colors[horizon], linestyle='--', linewidth=2.5, alpha=0.7)\n",
    "        \n",
    "        # Enhanced annotation\n",
    "        annotation_text = f\"${pred['predicted_price']:.2f}\\n\"\n",
    "        annotation_text += f\"{pred['price_change_pct']:+.2f}%\\n\"\n",
    "        annotation_text += f\"95% CI: ${pred['confidence_lower']:.2f}-${pred['confidence_upper']:.2f}\"\n",
    "        \n",
    "        ax1.annotate(annotation_text,\n",
    "                    xy=(future_date, pred['predicted_price']),\n",
    "                    xytext=(15, 15), textcoords='offset points',\n",
    "                    bbox=dict(boxstyle='round,pad=0.7', fc=colors[horizon], alpha=0.8, edgecolor='black', linewidth=1.5),\n",
    "                    fontsize=9, fontweight='bold', color='white',\n",
    "                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', lw=1.5))\n",
    "    \n",
    "    ax1.set_title(f'{ticker} - {company_name} - Price Analysis with AI Predictions & Confidence Intervals', \n",
    "                 fontsize=18, fontweight='bold', pad=25)\n",
    "    ax1.legend(loc='upper left', fontsize=11, framealpha=0.9)\n",
    "    ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax1.set_ylabel('Price ($)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 2. Volume Analysis\n",
    "    ax2 = fig.add_subplot(gs[2, :])\n",
    "    colors_vol = ['red' if data_clean['Close'].iloc[i] < data_clean['Close'].iloc[i-1] else 'green' \n",
    "                  for i in range(1, len(data_clean))]\n",
    "    colors_vol = ['gray'] + colors_vol\n",
    "    \n",
    "    ax2.bar(data_clean.index, data_clean['Volume'], color=colors_vol, alpha=0.6, label='Volume')\n",
    "    ax2.plot(data_clean.index, data_clean['Volume_MA_20'], color='blue', linewidth=2.5, label='Volume MA 20')\n",
    "    ax2.plot(data_clean.index, data_clean['Volume_MA_50'], color='red', linewidth=2, label='Volume MA 50', alpha=0.7)\n",
    "    ax2.set_title('Trading Volume Analysis with Moving Averages', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(loc='upper left', fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax2.set_ylabel('Volume', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # 3. RSI Indicator\n",
    "    ax3 = fig.add_subplot(gs[3, 0])\n",
    "    ax3.plot(data_clean.index, data_clean['RSI_14'], color='purple', linewidth=2.5, label='RSI (14)')\n",
    "    ax3.axhline(70, color='red', linestyle='--', alpha=0.7, linewidth=2, label='Overbought (70)')\n",
    "    ax3.axhline(30, color='green', linestyle='--', alpha=0.7, linewidth=2, label='Oversold (30)')\n",
    "    ax3.axhline(50, color='gray', linestyle=':', alpha=0.5, linewidth=1.5)\n",
    "    ax3.fill_between(data_clean.index, 30, 70, alpha=0.1, color='gray')\n",
    "    ax3.set_title('RSI (Relative Strength Index)', fontsize=13, fontweight='bold')\n",
    "    ax3.set_ylim(0, 100)\n",
    "    ax3.legend(loc='upper left', fontsize=9)\n",
    "    ax3.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax3.set_ylabel('RSI', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # 4. MACD Indicator\n",
    "    ax4 = fig.add_subplot(gs[3, 1])\n",
    "    ax4.plot(data_clean.index, data_clean['MACD'], color='blue', linewidth=2.5, label='MACD')\n",
    "    ax4.plot(data_clean.index, data_clean['MACD_Signal'], color='red', linewidth=2.5, label='Signal Line')\n",
    "    \n",
    "    # Color histogram bars based on value\n",
    "    colors_macd = ['green' if val > 0 else 'red' for val in data_clean['MACD_Histogram']]\n",
    "    ax4.bar(data_clean.index, data_clean['MACD_Histogram'], color=colors_macd, alpha=0.4, label='Histogram')\n",
    "    ax4.axhline(0, color='black', linestyle='-', linewidth=1)\n",
    "    ax4.set_title('MACD (Moving Average Convergence Divergence)', fontsize=13, fontweight='bold')\n",
    "    ax4.legend(loc='upper left', fontsize=9)\n",
    "    ax4.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax4.set_ylabel('MACD', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # 5. Stochastic Oscillator\n",
    "    ax5 = fig.add_subplot(gs[4, 0])\n",
    "    ax5.plot(data_clean.index, data_clean['Stochastic_%K'], color='blue', linewidth=2, label='%K')\n",
    "    ax5.plot(data_clean.index, data_clean['Stochastic_%D'], color='red', linewidth=2, label='%D')\n",
    "    ax5.axhline(80, color='red', linestyle='--', alpha=0.6, linewidth=1.5)\n",
    "    ax5.axhline(20, color='green', linestyle='--', alpha=0.6, linewidth=1.5)\n",
    "    ax5.fill_between(data_clean.index, 20, 80, alpha=0.1, color='gray')\n",
    "    ax5.set_title('Stochastic Oscillator', fontsize=13, fontweight='bold')\n",
    "    ax5.set_ylim(0, 100)\n",
    "    ax5.legend(loc='upper left', fontsize=9)\n",
    "    ax5.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax5.set_ylabel('Stochastic', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # 6. ADX (Trend Strength)\n",
    "    ax6 = fig.add_subplot(gs[4, 1])\n",
    "    ax6.plot(data_clean.index, data_clean['ADX'], color='purple', linewidth=2.5, label='ADX')\n",
    "    ax6.axhline(25, color='orange', linestyle='--', alpha=0.7, linewidth=2, label='Strong Trend (25)')\n",
    "    ax6.axhline(50, color='red', linestyle='--', alpha=0.7, linewidth=2, label='Very Strong (50)')\n",
    "    ax6.fill_between(data_clean.index, 25, 100, alpha=0.1, color='green')\n",
    "    ax6.set_title('ADX (Average Directional Index) - Trend Strength', fontsize=13, fontweight='bold')\n",
    "    ax6.set_ylim(0, 100)\n",
    "    ax6.legend(loc='upper left', fontsize=9)\n",
    "    ax6.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax6.set_ylabel('ADX', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # 7. Comprehensive Prediction Summary\n",
    "    ax7 = fig.add_subplot(gs[5, :])\n",
    "    ax7.axis('off')\n",
    "    \n",
    "    # Create detailed summary\n",
    "    summary_text = f\"ü§ñ ENHANCED AI PREDICTION SUMMARY - {ticker} ({company_name})\\n\\n\"\n",
    "    summary_text += f\"{'='*90}\\n\"\n",
    "    summary_text += f\"üí∞ CURRENT MARKET DATA\\n\"\n",
    "    summary_text += f\"{'='*90}\\n\"\n",
    "    summary_text += f\"Current Price: ${current_price:.2f} | \"\n",
    "    summary_text += f\"Analysis Date: {last_date.strftime('%Y-%m-%d')} | \"\n",
    "    summary_text += f\"Data Points: {len(data_clean)}\\n\\n\"\n",
    "    \n",
    "    summary_text += f\"{'='*90}\\n\"\n",
    "    summary_text += f\"üìà AI PREDICTIONS WITH CONFIDENCE INTERVALS (95% CI)\\n\"\n",
    "    summary_text += f\"{'='*90}\\n\"\n",
    "    \n",
    "    for horizon, pred in predictions.items():\n",
    "        change_emoji = \"üöÄ\" if pred['price_change_pct'] > 0 else \"üìâ\"\n",
    "        summary_text += f\"\\n{change_emoji} {horizon.upper()}:\\n\"\n",
    "        summary_text += f\"   Target Price: ${pred['predicted_price']:.2f} \"\n",
    "        summary_text += f\"(Change: ${pred['price_change']:+.2f} | {pred['price_change_pct']:+.2f}%)\\n\"\n",
    "        summary_text += f\"   95% Confidence: ${pred['confidence_lower']:.2f} - ${pred['confidence_upper']:.2f} \"\n",
    "        summary_text += f\"(¬±${pred['prediction_std']:.2f})\\n\"\n",
    "        \n",
    "        # Enhanced recommendation logic\n",
    "        pct = pred['price_change_pct']\n",
    "        if pct > 10:\n",
    "            recommendation = \"STRONG BUY üöÄüöÄüöÄ\"\n",
    "            action = \"High conviction buy opportunity\"\n",
    "        elif pct > 5:\n",
    "            recommendation = \"STRONG BUY üöÄüöÄ\"\n",
    "            action = \"Excellent buy signal\"\n",
    "        elif pct > 2:\n",
    "            recommendation = \"BUY üìà\"\n",
    "            action = \"Good entry point\"\n",
    "        elif pct > -2:\n",
    "            recommendation = \"HOLD ‚öñÔ∏è\"\n",
    "            action = \"Maintain current position\"\n",
    "        elif pct > -5:\n",
    "            recommendation = \"SELL üìâ\"\n",
    "            action = \"Consider reducing position\"\n",
    "        elif pct > -10:\n",
    "            recommendation = \"STRONG SELL üîªüîª\"\n",
    "            action = \"Exit position recommended\"\n",
    "        else:\n",
    "            recommendation = \"STRONG SELL üîªüîªüîª\"\n",
    "            action = \"Immediate exit recommended\"\n",
    "        \n",
    "        summary_text += f\"   ‚Üí {recommendation} - {action}\\n\"\n",
    "    \n",
    "    summary_text += f\"\\n{'='*90}\\n\"\n",
    "    summary_text += f\"üìä MODEL PERFORMANCE METRICS\\n\"\n",
    "    summary_text += f\"{'='*90}\\n\"\n",
    "    \n",
    "    for horizon_key, metrics in predictor.training_metrics.items():\n",
    "        horizon_name = horizon_key.replace('_', ' ')\n",
    "        summary_text += f\"\\n{horizon_name}:\\n\"\n",
    "        summary_text += f\"   MAE: ${metrics['mae']:.2f} | \"\n",
    "        summary_text += f\"RMSE: ${metrics['rmse']:.2f} | \"\n",
    "        summary_text += f\"R¬≤: {metrics['r2_score']:.3f} | \"\n",
    "        summary_text += f\"MAPE: {metrics['mape']:.2f}%\\n\"\n",
    "        summary_text += f\"   Directional Accuracy: {metrics['directional_accuracy']:.1f}% | \"\n",
    "        summary_text += f\"Ensemble: RF={metrics['ensemble_weights']['rf']:.2f}, \"\n",
    "        summary_text += f\"GB={metrics['ensemble_weights']['gb']:.2f}, \"\n",
    "        summary_text += f\"Ridge={metrics['ensemble_weights']['ridge']:.2f}\\n\"\n",
    "    \n",
    "    summary_text += f\"\\n{'='*90}\\n\"\n",
    "    summary_text += \"‚ö†Ô∏è  DISCLAIMER: Predictions are based on historical patterns and technical analysis.\\n\"\n",
    "    summary_text += \"    Past performance does not guarantee future results. Always conduct your own research.\\n\"\n",
    "    summary_text += f\"{'='*90}\\n\"\n",
    "    \n",
    "    ax7.text(0.5, 0.5, summary_text, transform=ax7.transAxes,\n",
    "            fontsize=9.5, verticalalignment='center', horizontalalignment='center',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.9, \n",
    "                     edgecolor='darkblue', linewidth=2, pad=1.5),\n",
    "            fontfamily='monospace', fontweight='bold')\n",
    "    \n",
    "    plt.savefig(f'Training/charts/{ticker}_enhanced_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úÖ Saved: Training/charts/{ticker}_enhanced_analysis.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Interactive Plotly Chart\n",
    "    print(\"üìä Creating interactive chart...\")\n",
    "    plot_data = data_clean.reset_index()\n",
    "    \n",
    "    fig2 = go.Figure()\n",
    "    \n",
    "    # Candlestick\n",
    "    fig2.add_trace(go.Candlestick(\n",
    "        x=plot_data['Date'],\n",
    "        open=plot_data['Open'],\n",
    "        high=plot_data['High'],\n",
    "        low=plot_data['Low'],\n",
    "        close=plot_data['Close'],\n",
    "        name='Price',\n",
    "        increasing_line_color='green',\n",
    "        decreasing_line_color='red'\n",
    "    ))\n",
    "    \n",
    "    # Moving averages\n",
    "    fig2.add_trace(go.Scatter(x=plot_data['Date'], y=plot_data['MA_50'],\n",
    "                             name='MA 50', line=dict(color='red', width=2)))\n",
    "    fig2.add_trace(go.Scatter(x=plot_data['Date'], y=plot_data['MA_200'],\n",
    "                             name='MA 200', line=dict(color='green', width=2)))\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    fig2.add_trace(go.Scatter(x=plot_data['Date'], y=plot_data['BB_Upper_20'],\n",
    "                             name='BB Upper', line=dict(color='gray', width=1, dash='dash'),\n",
    "                             showlegend=True))\n",
    "    fig2.add_trace(go.Scatter(x=plot_data['Date'], y=plot_data['BB_Lower_20'],\n",
    "                             name='BB Lower', line=dict(color='gray', width=1, dash='dash'),\n",
    "                             fill='tonexty', fillcolor='rgba(128,128,128,0.1)',\n",
    "                             showlegend=True))\n",
    "    \n",
    "    # Add prediction points with confidence intervals\n",
    "    for horizon, pred in predictions.items():\n",
    "        future_date = last_date + timedelta(days=offsets[horizon])\n",
    "        \n",
    "        # Prediction marker\n",
    "        fig2.add_trace(go.Scatter(\n",
    "            x=[future_date],\n",
    "            y=[pred['predicted_price']],\n",
    "            mode='markers+text',\n",
    "            name=f'{horizon} Prediction',\n",
    "            marker=dict(size=20, symbol='star', color=colors[horizon], \n",
    "                       line=dict(color='black', width=2)),\n",
    "            text=[f\"${pred['predicted_price']:.2f}<br>{pred['price_change_pct']:+.2f}%\"],\n",
    "            textposition=\"top center\",\n",
    "            textfont=dict(size=12, color=colors[horizon], family='Arial Black')\n",
    "        ))\n",
    "        \n",
    "        # Confidence interval\n",
    "        fig2.add_trace(go.Scatter(\n",
    "            x=[future_date, future_date, future_date],\n",
    "            y=[pred['confidence_lower'], pred['predicted_price'], pred['confidence_upper']],\n",
    "            mode='lines',\n",
    "            name=f'{horizon} CI',\n",
    "            line=dict(color=colors[horizon], width=0),\n",
    "            showlegend=False,\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                symmetric=False,\n",
    "                array=[pred['confidence_upper'] - pred['predicted_price']],\n",
    "                arrayminus=[pred['predicted_price'] - pred['confidence_lower']],\n",
    "                color=colors[horizon],\n",
    "                thickness=3,\n",
    "                width=10\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        # Prediction line\n",
    "        fig2.add_trace(go.Scatter(\n",
    "            x=[last_date, future_date],\n",
    "            y=[current_price, pred['predicted_price']],\n",
    "            mode='lines',\n",
    "            name=f'{horizon} Path',\n",
    "            line=dict(color=colors[horizon], width=3, dash='dash'),\n",
    "            showlegend=False\n",
    "        ))\n",
    "    \n",
    "    fig2.update_layout(\n",
    "        title=dict(\n",
    "            text=f'{ticker} - {company_name} - Interactive Technical Analysis with AI Predictions',\n",
    "            font=dict(size=20, color='darkblue', family='Arial Black')\n",
    "        ),\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price ($)',\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        height=800,\n",
    "        template='plotly_white',\n",
    "        hovermode='x unified',\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\",\n",
    "            y=0.99,\n",
    "            xanchor=\"left\",\n",
    "            x=0.01,\n",
    "            bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "            bordercolor=\"black\",\n",
    "            borderwidth=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig2.write_html(f'Training/charts/{ticker}_interactive_predictions.html')\n",
    "    print(f\"‚úÖ Saved: Training/charts/{ticker}_interactive_predictions.html\")\n",
    "    fig2.show()\n",
    "    \n",
    "    print(\"‚úÖ All visualizations generated successfully!\")\n",
    "\n",
    "#-------------------[MAIN EXECUTION]-----------------------#\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    create_directories()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üöÄ ENHANCED STOCK PRICE PREDICTION SYSTEM WITH ENSEMBLE AI\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"üìå Features: Multi-Model Ensemble | Advanced Technical Analysis | Confidence Intervals\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Display available stocks\n",
    "    print(\"\\nüìä AVAILABLE STOCKS FOR ANALYSIS:\")\n",
    "    print(\"-\"*80)\n",
    "    stocks_list = list(load_stock_list().items())\n",
    "    for i in range(0, len(stocks_list), 3):\n",
    "        row = stocks_list[i:i+3]\n",
    "        line = \"   \"\n",
    "        for symbol, name in row:\n",
    "            line += f\"{symbol:8} - {name[:30]:30}   \"\n",
    "        print(line)\n",
    "    \n",
    "    # Get user input\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    search = input(\"üîç Enter stock symbol or company name (press Enter for AAPL): \").strip()\n",
    "    \n",
    "    if not search:\n",
    "        print(\"‚úÖ Using default: AAPL - Apple Inc.\")\n",
    "        ticker, company_name = 'AAPL', 'Apple Inc.'\n",
    "    else:\n",
    "        matches = find_stock(search)\n",
    "        if not matches:\n",
    "            print(f\"‚ùå No matches found for '{search}'. Using AAPL as default.\")\n",
    "            ticker, company_name = 'AAPL', 'Apple Inc.'\n",
    "        elif len(matches) == 1:\n",
    "            ticker, company_name = list(matches.items())[0]\n",
    "            print(f\"‚úÖ Found: {ticker} - {company_name}\")\n",
    "        else:\n",
    "            print(f\"\\nüîç Found {len(matches)} matches:\")\n",
    "            match_list = list(matches.items())\n",
    "            for i, (symbol, name) in enumerate(match_list, 1):\n",
    "                print(f\"   {i}. {symbol:8} - {name}\")\n",
    "            \n",
    "            try:\n",
    "                choice = int(input(f\"\\nüëâ Select stock (1-{len(match_list)}): \"))\n",
    "                if 1 <= choice <= len(match_list):\n",
    "                    ticker, company_name = match_list[choice - 1]\n",
    "                else:\n",
    "                    print(\"‚ùå Invalid choice. Using first match.\")\n",
    "                    ticker, company_name = match_list[0]\n",
    "            except (ValueError, IndexError):\n",
    "                print(\"‚ùå Invalid input. Using first match.\")\n",
    "                ticker, company_name = match_list[0]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"‚úÖ SELECTED: {ticker} - {company_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Download data\n",
    "    print(\"\\nüì• Downloading historical stock data...\")\n",
    "    try:\n",
    "        data = yf.download(ticker, period='5y', auto_adjust=True, progress=False)\n",
    "        \n",
    "        if data.empty:\n",
    "            print(\"‚ùå No data downloaded. Please check your internet connection or ticker symbol.\")\n",
    "            return\n",
    "        \n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            data.columns = data.columns.get_level_values(0)\n",
    "        \n",
    "        print(f\"‚úÖ Successfully downloaded {len(data)} trading days\")\n",
    "        print(f\"üìÖ Date range: {data.index[0].strftime('%Y-%m-%d')} to {data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        # Save raw data\n",
    "        data.to_csv(f\"Training/stock_data/{ticker}_raw_data.csv\")\n",
    "        print(f\"üíæ Raw data saved: Training/stock_data/{ticker}_raw_data.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading data: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize enhanced predictor\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ü§ñ TRAINING ENHANCED ENSEMBLE AI MODEL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    predictor = EnhancedStockPricePredictor()\n",
    "    predictor.ticker = ticker\n",
    "    predictor.company_name = company_name\n",
    "    \n",
    "    # Train for different time horizons\n",
    "    time_horizons = ['1_Day', '5_Days', '21_Days']\n",
    "    horizon_names = ['1 Day', '1 Week', '1 Month']\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    for horizon, name in zip(time_horizons, horizon_names):\n",
    "        print(f\"\\n{'‚îÄ'*80}\")\n",
    "        if predictor.train_ensemble_model(data, horizon):\n",
    "            prediction = predictor.predict_future(data, horizon)\n",
    "            if prediction:\n",
    "                predictions[name] = prediction\n",
    "                print(f\"‚úÖ {name} prediction completed successfully\")\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìà PREDICTION RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if isinstance(data['Close'], pd.DataFrame):\n",
    "        current_price = data['Close'].iloc[-1].values[0]\n",
    "    else:\n",
    "        current_price = data['Close'].iloc[-1]\n",
    "    \n",
    "    print(f\"\\nüí∞ Current Price: ${current_price:.2f}\")\n",
    "    print(f\"üìÖ As of: {data.index[-1].strftime('%Y-%m-%d')}\\n\")\n",
    "    \n",
    "    for horizon, pred in predictions.items():\n",
    "        print(f\"{'‚îÄ'*80}\")\n",
    "        print(f\"üéØ {horizon.upper()} FORECAST:\")\n",
    "        print(f\"{'‚îÄ'*80}\")\n",
    "        print(f\"   Predicted Price:    ${pred['predicted_price']:.2f}\")\n",
    "        print(f\"   Expected Change:    ${pred['price_change']:+.2f} ({pred['price_change_pct']:+.2f}%)\")\n",
    "        print(f\"   95% Confidence:     ${pred['confidence_lower']:.2f} - ${pred['confidence_upper']:.2f}\")\n",
    "        print(f\"   Std Deviation:      ¬±${pred['prediction_std']:.2f}\")\n",
    "        \n",
    "        # Enhanced recommendation\n",
    "        pct = pred['price_change_pct']\n",
    "        if pct > 10:\n",
    "            rec = \"üöÄüöÄüöÄ STRONG BUY - High conviction opportunity\"\n",
    "        elif pct > 5:\n",
    "            rec = \"üöÄüöÄ STRONG BUY - Excellent entry point\"\n",
    "        elif pct > 2:\n",
    "            rec = \"üìà BUY - Good buying opportunity\"\n",
    "        elif pct > -2:\n",
    "            rec = \"‚öñÔ∏è  HOLD - Maintain current position\"\n",
    "        elif pct > -5:\n",
    "            rec = \"üìâ SELL - Consider reducing position\"\n",
    "        elif pct > -10:\n",
    "            rec = \"üîªüîª STRONG SELL - Exit recommended\"\n",
    "        else:\n",
    "            rec = \"üîªüîªüîª STRONG SELL - Immediate exit advised\"\n",
    "        \n",
    "        print(f\"   Recommendation:     {rec}\\n\")\n",
    "    \n",
    "    # Visualizations\n",
    "    print(\"=\"*80)\n",
    "    print(\"üìä GENERATING VISUALIZATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    visualize_with_predictions(data, ticker, company_name, predictions, predictor)\n",
    "    \n",
    "    # Save models\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üíæ SAVING MODELS AND METADATA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Save predictor\n",
    "        joblib.dump(predictor, f'Training/models/{ticker}_predictor.pkl')\n",
    "        print(f\"‚úÖ Model saved: Training/models/{ticker}_predictor.pkl\")\n",
    "        \n",
    "        joblib.dump(predictor, 'Training/models/main.pkl')\n",
    "        print(f\"‚úÖ Main model saved: Training/models/main.pkl\")\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            'ticker': ticker,\n",
    "            'company_name': company_name,\n",
    "            'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'data_points': len(data),\n",
    "            'date_range': f\"{data.index[0].strftime('%Y-%m-%d')} to {data.index[-1].strftime('%Y-%m-%d')}\",\n",
    "            'predictions': predictions,\n",
    "            'metrics': predictor.training_metrics,\n",
    "            'feature_importance': predictor.feature_importance.to_dict() if predictor.feature_importance is not None else None\n",
    "        }\n",
    "        \n",
    "        joblib.dump(metadata, f'Training/models/{ticker}_metadata.pkl')\n",
    "        print(f\"‚úÖ Metadata saved: Training/models/{ticker}_metadata.pkl\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving models: {e}\")\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ ANALYSIS COMPLETE - SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìä Stock Analyzed:        {ticker} - {company_name}\")\n",
    "    print(f\"üìà Historical Data:       {len(data)} trading days\")\n",
    "    print(f\"üéØ Prediction Horizons:   {len(predictions)} timeframes\")\n",
    "    print(f\"ü§ñ Model Type:            Ensemble (Random Forest + Gradient Boosting + Ridge)\")\n",
    "    print(f\"üìâ Technical Indicators:  50+ advanced features\")\n",
    "    print(f\"üìä Charts Generated:      Static PNG + Interactive HTML\")\n",
    "    print(f\"üíæ Files Saved:           {ticker}_enhanced_analysis.png, {ticker}_interactive_predictions.html\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üìÇ GENERATED FILES:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"   üìä Charts:\")\n",
    "    print(f\"      ‚îú‚îÄ Training/charts/{ticker}_enhanced_analysis.png\")\n",
    "    print(f\"      ‚îî‚îÄ Training/charts/{ticker}_interactive_predictions.html\")\n",
    "    print(f\"   üíæ Data:\")\n",
    "    print(f\"      ‚îî‚îÄ Training/stock_data/{ticker}_raw_data.csv\")\n",
    "    print(f\"   ü§ñ Models:\")\n",
    "    print(f\"      ‚îú‚îÄ Training/models/{ticker}_predictor.pkl\")\n",
    "    print(f\"      ‚îú‚îÄ Training/models/{ticker}_metadata.pkl\")\n",
    "    print(f\"      ‚îî‚îÄ Training/models/main.pkl\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üîÑ QUICK RELOAD INSTRUCTIONS:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"   To reload and use this trained model:\")\n",
    "    print(\"   ```python\")\n",
    "    print(\"   predictor, predictions = load_and_predict('Training/models/main.pkl')\")\n",
    "    print(\"   # or\")\n",
    "    print(f\"   predictor, predictions = load_and_predict('Training/models/{ticker}_predictor.pkl', '{ticker}')\")\n",
    "    print(\"   ```\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"‚ö†Ô∏è  IMPORTANT DISCLAIMER\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"   This tool provides predictions based on historical patterns and technical\")\n",
    "    print(\"   analysis. Stock markets are inherently unpredictable. Past performance does\")\n",
    "    print(\"   not guarantee future results. Always conduct thorough research and consult\")\n",
    "    print(\"   with financial advisors before making investment decisions.\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "#-------------------[LOAD AND USE MODEL FUNCTION]-----------------------#\n",
    "def load_and_predict(model_path='Training/models/main.pkl', ticker=None):\n",
    "    \"\"\"\n",
    "    Load a saved model and make new predictions\n",
    "    \n",
    "    Parameters:\n",
    "        model_path (str): Path to the saved model file\n",
    "        ticker (str): Stock ticker symbol (optional, will use stored ticker if None)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (predictor, predictions) or (None, None) if error\n",
    "    \n",
    "    Example:\n",
    "        >>> predictor, predictions = load_and_predict()\n",
    "        >>> predictor, predictions = load_and_predict('Training/models/AAPL_predictor.pkl', 'AAPL')\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Loading model from {model_path}...\")\n",
    "    \n",
    "    try:\n",
    "        predictor = joblib.load(model_path)\n",
    "        print(f\"‚úÖ Model loaded successfully!\")\n",
    "        \n",
    "        if ticker is None:\n",
    "            ticker = predictor.ticker\n",
    "        \n",
    "        print(f\"üì• Downloading latest data for {ticker}...\")\n",
    "        data = yf.download(ticker, period='1y', auto_adjust=True, progress=False)\n",
    "        \n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            data.columns = data.columns.get_level_values(0)\n",
    "        \n",
    "        print(f\"‚úÖ Downloaded {len(data)} days of data\")\n",
    "        \n",
    "        # Make predictions\n",
    "        print(f\"\\nüéØ Generating predictions...\")\n",
    "        \n",
    "        time_horizons = ['1_Day', '5_Days', '21_Days']\n",
    "        horizon_names = ['1 Day', '1 Week', '1 Month']\n",
    "        \n",
    "        predictions = {}\n",
    "        for horizon, name in zip(time_horizons, horizon_names):\n",
    "            prediction = predictor.predict_future(data, horizon)\n",
    "            if prediction:\n",
    "                predictions[name] = prediction\n",
    "        \n",
    "        # Display results\n",
    "        if isinstance(data['Close'], pd.DataFrame):\n",
    "            current_price = data['Close'].iloc[-1].values[0]\n",
    "        else:\n",
    "            current_price = data['Close'].iloc[-1]\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üí∞ Current Price: ${current_price:.2f}\")\n",
    "        print(f\"üìÖ As of: {data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        for horizon, pred in predictions.items():\n",
    "            print(f\"üéØ {horizon.upper()} PREDICTION:\")\n",
    "            print(f\"   Target: ${pred['predicted_price']:.2f} | \"\n",
    "                  f\"Change: ${pred['price_change']:+.2f} ({pred['price_change_pct']:+.2f}%)\")\n",
    "            print(f\"   95% CI: ${pred['confidence_lower']:.2f} - ${pred['confidence_upper']:.2f}\")\n",
    "            \n",
    "            pct = pred['price_change_pct']\n",
    "            if pct > 5:\n",
    "                rec = \"üöÄ STRONG BUY\"\n",
    "            elif pct > 2:\n",
    "                rec = \"üìà BUY\"\n",
    "            elif pct > -2:\n",
    "                rec = \"‚öñÔ∏è  HOLD\"\n",
    "            elif pct > -5:\n",
    "                rec = \"üìâ SELL\"\n",
    "            else:\n",
    "                rec = \"üîª STRONG SELL\"\n",
    "            \n",
    "            print(f\"   Recommendation: {rec}\\n\")\n",
    "        \n",
    "        return predictor, predictions\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Model file not found: {model_path}\")\n",
    "        print(f\"   Please train a model first by running main()\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "#-------------------[RUN THE PROGRAM]-----------------------#\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è  Program interrupted by user\")\n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå Missing required package: {e}\")\n",
    "        print(\"\\nüí° Install required packages:\")\n",
    "        print(\"   pip install yfinance scikit-learn pandas numpy matplotlib plotly joblib\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"\\nüí° Please check your internet connection and try again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
